<!doctype html>
<html lang="en">

    <head>

        <!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <!-- pygments CSS -->
        <!-- command to create pygments.css: $ pygmentize -S default -f html > pygments.css-->
        <link rel="stylesheet" type="text/css" href="/static/pygments.css">

        <!-- Bootstrap CSS -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">

        <title>Freezeyt blog</title>

    </head>

    <body>

        <div class="container">
            

<h1>Tests Reorganization and Parametrization</h1>
<p><strong><a href="https://www.youtube.com/watch?v=JQMvylmLs2Q&amp;list=PLFt-PM7J_H3EU5Oez3ZSVjY5pZJttP2lT&amp;index=10&amp;t=0s&amp;ab_channel=encukou">9th Online Meeting</a>, August 31, 2020</strong></p>
<p><strong><em>Mentor: Petr Viktorin</em></strong></p>
<h3>Checking New PRs</h3>
<ul>
<li>Blog 6, change some images into code snippets.</li>
<li>Test_parse_absolute_url, add tests for netloc, port and path.</li>
</ul>
<p><em>00hr:18mins</em></p>
<p>Petr started to reorganize tests on a separate branch because it was not to be done in one shot. In order not to lose the work done he commited it as WIP (work in progress) without pushing it.
To continue working on it he switched to the <code>reorganize tests</code> branch.</p>
<h3>Rebase the reorganize-tests branch to the master in order not to lose any history.</h3>
<p>Each commit in Git represents the state of the whole project. <code>Git show</code> and <code>gitk --all</code> both display all the changes since the last commit. In the background however it actually saves the whole content/state of each commit. Saving the whole state of all commits makes it possible for Git to display all that happened within each commit. In reality, it compares the state of the previous/parent commit, and the state of the current commit by listing the <code>diff --git a/</code> of all files from both commits.</p>
<p>To do the <code>git rebase master</code>, Git takes the diff or all changes from the commit and attempts to apply the same changes to the current master. More precisely, Git creates a new commit, goes file by file and tries to apply all changes until a conflict appears or until all changes are applied to the master.</p>
<p>
<img src="/article_image/rebase_commits.png" alt="Rebase commits" >
</p>
<h3>Good Rebase - Conflict Example</h3>
<p><em>00hr:21min</em></p>
<p>
<img src="/article_image/rebase_conflict.png" alt="Rebase conflict" >
</p>
<p>The "modify/delete" means that <code>test_demo.py</code> changed in the master and the same file was deleted from the reorganize-tests branch which is being rebased.</p>
<p>
<img src="/article_image/git_status_rebase.png" alt="Git status rebase" >
</p>
<p>"Version HEAD of test_demo.py left in tree" means that the file <code>test_demo.py</code> was left in the working tree although it was deleted/renamed into <code>test_expected_output.py</code> in the reorganize-tests branch. This change was done because test_demo.py contained repetitive tests which import an app, freeze the same and than check if the app does what it was supposed to do.</p>
<p><strong><em>Future Issue:</em></strong>
<em>00hr:24min</em></p>
<p>The new tests do not assert <code>test_flask_url_for_custom_prefix_without_port(tmp_path)</code>.</p>
<p>After all conflicts are resolved and the changes are commited just <code>git rebase --continue</code> to complete the rebase. Finally, reorganize-tests is established on the master branch.</p>
<p>
<img src="/article_image/after_rebase.png" alt="After rebase" >
</p>
<h3>Add test_expected_output comparing freeze output to expected output</h3>
<p><em>00hr:27min</em></p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">importlib</span>
<span class="kn">from</span> <span class="nn">freezeyt</span> <span class="kn">import</span> <span class="n">freeze</span>

<span class="k">def</span> <span class="nf">test_output</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="n">module</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;demo app&#39;</span><span class="p">):</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">module_name</span><span class="p">)</span> <span class="c1">#naimportuje si applikace ze importlib</span>
    <span class="n">app</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">app</span>

    <span class="n">freeze</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">tmp_path</span><span class="p">)</span>

    <span class="n">expected</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s1">&#39;fixtures&#39;</span> <span class="o">/</span> <span class="n">module_name</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span>

    <span class="n">cmp</span> <span class="o">=</span> <span class="n">filecmp</span><span class="o">.</span><span class="n">dircmp</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="p">[])</span> <span class="c1">#comparison</span>

    <span class="k">assert</span> <span class="kc">False</span>
</pre></div>
<p>At this point this test freezes an app from the demo_app module. Creates a variable <code>expected</code> (the path to the fixtures folder) in order to be able to compare it's content to the actual output of the freeze. We used <a href="https://docs.python.org/3/library/filecmp.html">filecmp</a> to make the comparison between what we froze and what is in the expected fixtures folder. Next it is needed to create the asserts for this test.</p>
<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">left_only</span><span class="p">)</span> <span class="c1">#files found only in the left folder (in this case tmp_path)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">right_only</span><span class="p">)</span> <span class="c1">#files found only in the right folder (in this case expected)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">diff_files</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">common_funny</span><span class="p">)</span> <span class="c1">#in case the same thing is a file on one side and a folder or smth. else on the other side</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">subdirs</span><span class="p">)</span> <span class="c1">#comparison of dictionaries {directory : content}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">diff_files</span><span class="p">)</span> <span class="c1">#different files on each side</span>
</pre></div>
<p>It is better to create an <a href="https://github.com/encukou/freezeyt/blob/0bbed56c3cc49f06451d0b89fb8537761403b976/tests/test_expected_output.py#L34-L37">assert_dirs_same</a> function which will do the comparison.</p>
<h3>Testing the Test - Comparing Directory Trees</h3>
<p><em>00hr:38min</em></p>
<p>Created folders <code>same</code> and <code>testdir</code>, inside the fixtures folder. <code>testdir</code> contains a file.txt with some random text, and a sub-folder with a file inside it. Inside the fixtures folder is a <code>dirs_same</code> folder containing all possible variations of testing folders which should cause the test to fail like <code>missing_file</code>, <code>extra_file</code>, <code>extra_in_subdir</code>, <code>missing_dir</code>, <code>missing_file_in_dir</code>, <code>same</code>, <code>funny</code>, <code>diff_files</code>.</p>
<p>
<img src="/article_image/testing_tree2.png" alt="Testing tree" >
</p>
<p>At this stage <code>test_assert_dirs_same</code> compares all these possible variations to both <code>testdir</code> and <code>same</code> since these two need to be identical for the tests to pass:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_assert_dirs_same</span><span class="p">():</span>
  <span class="n">fixture_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s1">&#39;fixtures&#39;</span> <span class="s1">&#39;dirs_same&#39;</span>
  <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">fixture_path</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;testdir&#39;</span><span class="p">,</span> <span class="s1">&#39;same&#39;</span><span class="p">):</span>
      <span class="n">assert_dirs_same</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">fixture_path</span> <span class="o">/</span> <span class="s1">&#39;testdir&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">):</span>
        <span class="n">assert_dirs_same</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">fixture_path</span> <span class="o">/</span> <span class="s1">&#39;testdir&#39;</span><span class="p">)</span>
</pre></div>
<p>Everytime <code>test_assert_dirs_same</code> fails we solve each failure and build the <code>assert_dirs_same</code> gradually. The first one that failed was funny so the appropriate assertion was added to <code>assert_dirs_same</code>:</p>
<div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">cmp</span><span class="o">.</span><span class="n">common_funny</span><span class="p">:</span>
  <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Funny dofferemces: </span><span class="si">{</span><span class="n">cmp</span><span class="o">.</span><span class="n">common_funny</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
<p>The same is done until all <code>test_assert_dirs_same</code> conditions pass without a failure.</p>
<h3>Testing Subdirectories - Calling a Function From Another Function</h3>
<p><em>00hr:54min</em></p>
<p>The test does not count on subdirectories so we need to find a way for each <code>subdir</code> to pass the <code>test_assert_dirs_same</code> as well. The best way to do this is to divide <code>assert_dirs_same</code> in two functions where one will be calling the other.</p>
<p>
<img src="/article_image/subdirs.png" alt="Testing Subdirectories" >
</p>
<p>In this case, <code>cmp</code> notes all files and folders that are within each folder using <code>filecmp.dircmp</code> and does the same again for each subfolder every time <a href="https://github.com/encukou/freezeyt/blob/0bbed56c3cc49f06451d0b89fb8537761403b976/tests/test_expected_output.py#L34%20-%20L60"><code>assert_dirs_same</code> calls ```assert_cmp_same</a>.</p>
<h3>Future ISSUE</h3>
<p><em>01hr:09min</em></p>
<p>Improve the description to AssertionErrors in <a href="https://github.com/encukou/freezeyt/blob/0bbed56c3cc49f06451d0b89fb8537761403b976/tests/test_expected_output.py#L39-L57">assert_cmp_same</a> gradually as further test failures appear. It would be good to get the absolute path to the folder where the failure happens for example.</p>
<p>When calling assert_dirs_same inside test_output we got an <code>AssertionError: Files does not have expected content: ['index.html']</code></p>
<h3>Gradually Improving Tests</h3>
<p>The following asks pytest to compare the expected and the output file to make it easier to locate the the difference:</p>
<div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">cmp</span><span class="o">.</span><span class="n">diff_files</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">cmp</span><span class="o">.</span><span class="n">diff_files</span><span class="p">:</span>
    <span class="n">path1</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">left</span><span class="p">)</span> <span class="o">/</span> <span class="n">filename</span>
    <span class="n">path2</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">right</span><span class="p">)</span> <span class="o">/</span> <span class="n">filename</span>
    <span class="k">assert</span> <span class="n">parh1</span><span class="o">.</span><span class="n">read_text</span><span class="p">()</span> <span class="o">==</span> <span class="n">path2</span><span class="o">.</span><span class="n">read_text</span><span class="p">()</span>
</pre></div>
<p>This provided the following:</p>
<p>
<img src="/article_image/diff_files_error_details.png" alt="diff_files_error_details" >
</p>
<h3>Interactive Rebase - complete control over the branch's commit history</h3>
<p><em>01hr:19min</em></p>
<p>Interactive rebase was used to merge the work_in_progress commit to reorganize tests. <code>$ git rebase --interactive &lt;branch_from_where_to_start&gt;</code></p>
<p>This way you get a list of a few commands to change your commits history:</p>
<p>
<img src="/article_image/interactive_rebase_commits2.png" alt="" >
</p>
<p>Reword lets you change the description of a commit and we squashed (melded) the two commits into one.</p>
<h3>Making sure no commits were lost - changing commit history</h3>
<p><em>01hr:25min</em></p>

<pre><code>$ git --reflog</code></pre>
<p>Shows the entire and complete history of commits which existed at any point in time, and makes it possible to retrieve lost commits:</p>
<p>
<img src="/article_image/git_reflog2.png" alt="Git reflog" >
</p>
<p>This history can be browsed using the commit name: <code>$ git show HEAD @ {3}</code> - where the history was three changes ago, or <code>$ git show HEAD@{3.weeks.ago}</code>. This way you can return to any of the changes at any point in he commit history. Also available <code>$ git log HEAD@{3.weeks.ago}</code> and <code>$ gitk --all HEAD@{3.weeks.ago}</code></p>
<h3>Make sure something is running in a special mode in order to generate the already corrected output (directly copied from the frozen output)</h3>
<p><em>01hr:33min</em></p>
<p>What we did so far compares the current frozen output to the expected output and we are supposed to fix the differences manually. We want the corrected output to be generated by a special mode. When we run the tests in this special mode the expected output is created on its own. How to ensure that tests are running in a special mode? How to pass some information to a running application?</p>
<p><strong>Two ways</strong></p>
<ol>
<li><p>Create a switch <code>$ python -m pytest -vv --create-data</code>. This switch triggers pytest to create the test data/expected output</p>
</li>
<li><p><code>$ export TEST_CREATE_EXPECTED_OUTPUT=1</code>, and than check if this environmental variable is not already set in the test. If yes, no need to compare, just copy the content of the frozen into the expected using a special module <a href="https://docs.python.org/2/library/shutil.html#shutil.copytree">shutil</a>:</p>

<pre><code> ```python
 if 'TEST_CREATE_EXPECTED_OUTPUT' in os.environ:
   shutil.copytree(tmp_path, expected)
 ```</code></pre>
</li>
</ol>
<p>From this point on, when adding a new tests we have to run them from 'TEST_CREATE_EXPECTED_OUTPUT' and afterwards check if the generated files contain the expected output.</p>
<h3>Parameterized tests - run the same test function over and over again using different values.</h3>
<p><em>01hr:47min</em></p>
<p>So far the tests run on one app only, and to test the rest of the demo_apps we could use the for cycle used in the <code>test_assert_dirs_same()</code>. However <strong><em>using a loop has a disadvantage in because it breaks a the first exception</em></strong>.
This is why @pytest.mark.parametrize: parametrizing test functions was used.</p>
<h3>Making two tests out of one function</h3>
<p><em>01hr:50min</em></p>
<p>The function takes the <code>dir_names</code> argument, add it to the path, and than use <code>@pytest.mark.parametrize('dir_names', ['difference', 'extra'])</code> setting the <code>dir_names</code> argument to 'difference' and 'extra'. Making two tests out of a single function. More precisely, a single test function receives and tests two different parameters, 'difference' and 'extra'.</p>
<p><a href="https://github.com/encukou/freezeyt/blob/0bbed56c3cc49f06451d0b89fb8537761403b976/tests/test_expected_output.py#L63-L74">test_assert_dirs_same</a> was changed accordingly, the fixture_path was made into a global variable named DIRS_SAME_FIXTURES and than we are able to iterate over it inside the test, which made it possible to test all of the apps from inside fixtures with this single test:</p>
<p>
<img src="/article_image/test_parametrized.png" alt="Test parametrization magic" >
</p>
<h3>Homework</h3>
<ul>
<li>Write doc strings (what it does and how to call it) to new test functions or comments (how it does it)</li>
<li><a href="https://github.com/encukou/freezeyt/issues/32">Issue#32</a></li>
<li>hledani odkazy ve CSS very complicated</li>
<li><a href="https://github.com/encukou/freezeyt/issues/39">Issue#39</a>, Petr will do it live</li>
<li>doc. string for freeze</li>
<li>Add to readme - what the prefix means</li>
<li>create blog app.</li>
<li>write tests for parse_absolute_url <a href="https://github.com/encukou/freezeyt/issues/45">issue#45</a> test the rest of the attributes, port and hostname.</li>
<li>New <a href="https://github.com/encukou/freezeyt/issues/50">issue#50</a>, Parametrize test_expected_output.test_output</li>
</ul>



        </div>

        <!-- Bootstrap JS, Popper.js, and jQuery -->
        <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>

    </body>

</html>